{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10293424,"sourceType":"datasetVersion","datasetId":6370577}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-30T00:44:49.779471Z","iopub.execute_input":"2025-03-30T00:44:49.779822Z","iopub.status.idle":"2025-03-30T00:44:57.530576Z","shell.execute_reply.started":"2025-03-30T00:44:49.779776Z","shell.execute_reply":"2025-03-30T00:44:57.529713Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-08T21:28:41.416560Z","iopub.execute_input":"2025-04-08T21:28:41.416799Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.getcwd()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train = '/kaggle/input/realwaste-dataset/splited dataset/train'\ndf_val = '/kaggle/input/realwaste-dataset/splited dataset/val'\ndf_test = '/kaggle/input/realwaste-dataset/splited dataset/test'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n\n# Check class distribution to avoid imbalance issues\nlabels = os.listdir(df_train)\nclass_counts = {label: len(os.listdir(os.path.join(df_train, label))) for label in labels}\nprint(\"Class distribution:\", class_counts)\n\n# Compute class weights\nclass_weight = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(list(class_counts.keys())),\n    y=np.concatenate([[label] * count for label, count in class_counts.items()])\n)\nclass_weight = dict(enumerate(class_weight))\nprint(\"Computed class weights:\", class_weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:24.615154Z","iopub.execute_input":"2025-04-04T20:08:24.615478Z","iopub.status.idle":"2025-04-04T20:08:24.632892Z","shell.execute_reply.started":"2025-04-04T20:08:24.615452Z","shell.execute_reply":"2025-04-04T20:08:24.632019Z"}},"outputs":[{"name":"stdout","text":"Class distribution: {'Metal': 474, 'Glass': 252, 'Paper': 300, 'Vegetation': 261, 'Cardboard': 276, 'Textile Trash': 190, 'Food Organics': 246, 'Plastic': 552, 'Miscellaneous Trash': 297}\nComputed class weights: {0: 1.146537842190016, 1: 1.2863595302619693, 2: 1.255731922398589, 3: 0.6676043131739334, 4: 1.0654695099139544, 5: 1.0548148148148149, 6: 0.573268921095008, 7: 1.6654970760233918, 8: 1.2124308216262238}\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob as gb\nsize = []\n\nfor label in os.listdir(df_train):\n    images_paths = gb.glob(str(df_train +'/'+label+'/*.jpg'))\n\n    for img_path in images_paths:\n        img = plt.imread(img_path)\n        img_shape = img.shape\n        size.append(img_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:27.253182Z","iopub.execute_input":"2025-04-04T20:08:27.253517Z","iopub.status.idle":"2025-04-04T20:08:40.337228Z","shell.execute_reply.started":"2025-04-04T20:08:27.253494Z","shell.execute_reply":"2025-04-04T20:08:40.336321Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"df = pd.DataFrame(size)\ndf.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:40.338250Z","iopub.execute_input":"2025-04-04T20:08:40.338544Z","iopub.status.idle":"2025-04-04T20:08:40.350547Z","shell.execute_reply.started":"2025-04-04T20:08:40.338520Z","shell.execute_reply":"2025-04-04T20:08:40.349574Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"0    1    2\n524  524  3    2848\nName: count, dtype: int64"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"size = []\n\nfor label in os.listdir(df_val):\n    images_paths = gb.glob(str(df_val +'/'+label+'/*.jpg'))\n\n    for img_path in images_paths:\n        img = plt.imread(img_path)\n        img_shape = img.shape\n        size.append(img_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:40.352709Z","iopub.execute_input":"2025-04-04T20:08:40.352919Z","iopub.status.idle":"2025-04-04T20:08:44.845995Z","shell.execute_reply.started":"2025-04-04T20:08:40.352901Z","shell.execute_reply":"2025-04-04T20:08:44.844971Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"df_va = pd.DataFrame(size)\ndf_va.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:44.847184Z","iopub.execute_input":"2025-04-04T20:08:44.847425Z","iopub.status.idle":"2025-04-04T20:08:44.858219Z","shell.execute_reply.started":"2025-04-04T20:08:44.847405Z","shell.execute_reply":"2025-04-04T20:08:44.857398Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0    1    2\n524  524  3    949\nName: count, dtype: int64"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"size = []\n\nfor label in os.listdir(df_test):\n    images_paths = gb.glob(str(df_test +'/'+label+'/*.jpg'))\n\n    for img_path in images_paths:\n        img = plt.imread(img_path)\n        img_shape = img.shape\n        size.append(img_shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:44.859173Z","iopub.execute_input":"2025-04-04T20:08:44.859500Z","iopub.status.idle":"2025-04-04T20:08:49.830888Z","shell.execute_reply.started":"2025-04-04T20:08:44.859465Z","shell.execute_reply":"2025-04-04T20:08:49.830062Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"df_tes = pd.DataFrame(size)\ndf_tes.value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:49.831755Z","iopub.execute_input":"2025-04-04T20:08:49.831991Z","iopub.status.idle":"2025-04-04T20:08:49.841221Z","shell.execute_reply.started":"2025-04-04T20:08:49.831970Z","shell.execute_reply":"2025-04-04T20:08:49.840463Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"0    1    2\n524  524  3    955\nName: count, dtype: int64"},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"train_generator","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Create ImageGenerators for training \ntrain_datagen = ImageDataGenerator(\n    rotation_range = 15, \n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    rescale = 1/255\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/input/realwaste-dataset/splited dataset/train',\n    target_size=(256, 256),  #  Fix: Resizing\n    batch_size = 32,\n    class_mode = 'categorical'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:49.842058Z","iopub.execute_input":"2025-04-04T20:08:49.842302Z","iopub.status.idle":"2025-04-04T20:08:49.955040Z","shell.execute_reply.started":"2025-04-04T20:08:49.842280Z","shell.execute_reply":"2025-04-04T20:08:49.954039Z"}},"outputs":[{"name":"stdout","text":"Found 2848 images belonging to 9 classes.\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"train_batch = train_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:49.957787Z","iopub.execute_input":"2025-04-04T20:08:49.958048Z","iopub.status.idle":"2025-04-04T20:08:49.962006Z","shell.execute_reply.started":"2025-04-04T20:08:49.958025Z","shell.execute_reply":"2025-04-04T20:08:49.960752Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"val_generator","metadata":{}},{"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale = 1/255)\nval_generator = val_datagen.flow_from_directory(\n    '/kaggle/input/realwaste-dataset/splited dataset/val',\n    target_size=(256, 256),  #  Fix: Resizing\n    batch_size = 32,\n    class_mode = 'categorical'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:49.962959Z","iopub.execute_input":"2025-04-04T20:08:49.963258Z","iopub.status.idle":"2025-04-04T20:08:50.010843Z","shell.execute_reply.started":"2025-04-04T20:08:49.963227Z","shell.execute_reply":"2025-04-04T20:08:50.010170Z"}},"outputs":[{"name":"stdout","text":"Found 949 images belonging to 9 classes.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"val_batch = val_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:50.011951Z","iopub.execute_input":"2025-04-04T20:08:50.012318Z","iopub.status.idle":"2025-04-04T20:08:50.016789Z","shell.execute_reply.started":"2025-04-04T20:08:50.012283Z","shell.execute_reply":"2025-04-04T20:08:50.015734Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"test_generator","metadata":{}},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1/255)\ntest_generator = test_datagen.flow_from_directory(\n    '/kaggle/input/realwaste-dataset/splited dataset/test',\n    target_size=(256, 256),  #  Fix: Resizing\n    batch_size = 32,\n    class_mode = 'categorical'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:50.017622Z","iopub.execute_input":"2025-04-04T20:08:50.017931Z","iopub.status.idle":"2025-04-04T20:08:50.065675Z","shell.execute_reply.started":"2025-04-04T20:08:50.017900Z","shell.execute_reply":"2025-04-04T20:08:50.064955Z"}},"outputs":[{"name":"stdout","text":"Found 955 images belonging to 9 classes.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"test_batch= test_generator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:50.066461Z","iopub.execute_input":"2025-04-04T20:08:50.066744Z","iopub.status.idle":"2025-04-04T20:08:50.070476Z","shell.execute_reply.started":"2025-04-04T20:08:50.066720Z","shell.execute_reply":"2025-04-04T20:08:50.069548Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_batch[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T00:02:33.794594Z","iopub.execute_input":"2025-04-04T00:02:33.794884Z","iopub.status.idle":"2025-04-04T00:02:34.283300Z","shell.execute_reply.started":"2025-04-04T00:02:33.794861Z","shell.execute_reply":"2025-04-04T00:02:34.282326Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"(array([[[[0.3830056 , 0.47241765, 0.60601234],\n          [0.4147835 , 0.4946622 , 0.6314347 ],\n          [0.41421714, 0.5007346 , 0.63529414],\n          ...,\n          [0.48636174, 0.53734213, 0.61185193],\n          [0.48847085, 0.53945124, 0.61396104],\n          [0.48475334, 0.5357337 , 0.61024356]],\n \n         [[0.37995476, 0.47058827, 0.6039216 ],\n          [0.40779603, 0.48977095, 0.6258447 ],\n          [0.41561463, 0.5000358 , 0.63529414],\n          ...,\n          [0.47248212, 0.5234625 , 0.5979723 ],\n          [0.47048402, 0.5214644 , 0.59253174],\n          [0.4791487 , 0.5301291 , 0.59842056]],\n \n         [[0.37925604, 0.47058827, 0.6039216 ],\n          [0.40080854, 0.4848797 , 0.6202547 ],\n          [0.41701213, 0.4993371 , 0.63529414],\n          ...,\n          [0.46073547, 0.5117159 , 0.5862257 ],\n          [0.46545556, 0.516436  , 0.5867416 ],\n          [0.4794623 , 0.5304427 , 0.5971094 ]],\n \n         ...,\n \n         [[0.64611274, 0.73238724, 0.87748533],\n          [0.6447145 , 0.730989  , 0.876087  ],\n          [0.6433161 , 0.7295906 , 0.8746886 ],\n          ...,\n          [0.6247797 , 0.70713264, 0.8287013 ],\n          [0.6213931 , 0.703746  , 0.8253147 ],\n          [0.636415  , 0.71876794, 0.84033656]],\n \n         [[0.6398323 , 0.7261068 , 0.87120485],\n          [0.6388249 , 0.7254902 , 0.8694157 ],\n          [0.6381257 , 0.7254902 , 0.86731815],\n          ...,\n          [0.6179543 , 0.70030725, 0.8218759 ],\n          [0.61686295, 0.69921595, 0.82078457],\n          [0.62564224, 0.7079952 , 0.8295638 ]],\n \n         [[0.63638383, 0.7254902 , 0.8620925 ],\n          [0.63568467, 0.7254902 , 0.859995  ],\n          [0.6359115 , 0.72579896, 0.8600583 ],\n          ...,\n          [0.62519956, 0.7075525 , 0.8291211 ],\n          [0.62893224, 0.7112852 , 0.83285385],\n          [0.63154954, 0.7139025 , 0.8354711 ]]],\n \n \n        [[[0.63396233, 0.6412719 , 0.5997353 ],\n          [0.6219132 , 0.62975633, 0.5866191 ],\n          [0.7866748 , 0.79451793, 0.7513807 ],\n          ...,\n          [0.802725  , 0.8184113 , 0.82233286],\n          [0.8417504 , 0.85743666, 0.8613582 ],\n          [0.88077575, 0.896462  , 0.9003836 ]],\n \n         [[0.70160806, 0.7079649 , 0.6692866 ],\n          [0.6133384 , 0.62118155, 0.5780443 ],\n          [0.7237928 , 0.7316359 , 0.6884987 ],\n          ...,\n          [0.89188236, 0.9008627 , 0.90701956],\n          [0.8910859 , 0.89767694, 0.9046303 ],\n          [0.89028955, 0.8944912 , 0.902241  ]],\n \n         [[0.7692539 , 0.77465796, 0.73883796],\n          [0.60476357, 0.6126067 , 0.56946945],\n          [0.6609108 , 0.6687539 , 0.62561667],\n          ...,\n          [0.80086994, 0.81203413, 0.8174631 ],\n          [0.77140176, 0.7849553 , 0.7895878 ],\n          [0.7489468 , 0.76463306, 0.76872563]],\n \n         ...,\n \n         [[0.69186664, 0.6957882 , 0.6691467 ],\n          [0.5624912 , 0.56641275, 0.5371173 ],\n          [0.69153935, 0.6955081 , 0.67249984],\n          ...,\n          [0.4955933 , 0.49951488, 0.46814233],\n          [0.59771645, 0.601638  , 0.5702654 ],\n          [0.6646097 , 0.66853124, 0.63715863]],\n \n         [[0.6104006 , 0.6094778 , 0.5871641 ],\n          [0.39482424, 0.3987458 , 0.36754486],\n          [0.60059077, 0.60451233, 0.58011955],\n          ...,\n          [0.54291046, 0.5459285 , 0.5145559 ],\n          [0.5691337 , 0.57305527, 0.5416827 ],\n          [0.64746004, 0.6513816 , 0.62000906]],\n \n         [[0.6324673 , 0.62854576, 0.60928744],\n          [0.5257232 , 0.52791095, 0.49913925],\n          [0.4730064 , 0.47764066, 0.4534805 ],\n          ...,\n          [0.5943594 , 0.5964246 , 0.56505203],\n          [0.54055095, 0.5444725 , 0.51309997],\n          [0.63031036, 0.6342319 , 0.6028594 ]]],\n \n \n        [[[0.37727946, 0.436103  , 0.5184559 ],\n          [0.36474225, 0.42356578, 0.50591874],\n          [0.36313134, 0.42195487, 0.50430787],\n          ...,\n          [0.4431373 , 0.5254902 , 0.64705884],\n          [0.4431373 , 0.5254902 , 0.64705884],\n          [0.4431373 , 0.5254902 , 0.64705884]],\n \n         [[0.37791657, 0.4367401 , 0.51909304],\n          [0.3660165 , 0.42484003, 0.50719297],\n          [0.3628128 , 0.42163634, 0.5039893 ],\n          ...,\n          [0.45228398, 0.53463686, 0.65620553],\n          [0.4534666 , 0.53581953, 0.65738815],\n          [0.45464918, 0.53700215, 0.65857077]],\n \n         [[0.3785537 , 0.4373772 , 0.5197302 ],\n          [0.36729074, 0.42611426, 0.5084672 ],\n          [0.36249426, 0.4213178 , 0.5036707 ],\n          ...,\n          [0.44700015, 0.5293531 , 0.6509217 ],\n          [0.44522622, 0.5275792 , 0.6491478 ],\n          [0.4434523 , 0.52580523, 0.64737386]],\n \n         ...,\n \n         [[0.5218509 , 0.5728313 , 0.6473411 ],\n          [0.50987124, 0.5608517 , 0.6353615 ],\n          [0.508849  , 0.5598295 , 0.6343393 ],\n          ...,\n          [0.5692203 , 0.6437301 , 0.7670982 ],\n          [0.5676807 , 0.6457239 , 0.7679564 ],\n          [0.56837475, 0.6507277 , 0.7722963 ]],\n \n         [[0.52455014, 0.5755306 , 0.6500404 ],\n          [0.5184415 , 0.5694219 , 0.6439317 ],\n          [0.5063516 , 0.557332  , 0.6318418 ],\n          ...,\n          [0.5604654 , 0.6349752 , 0.7526223 ],\n          [0.5601512 , 0.63755727, 0.7566524 ],\n          [0.56348455, 0.6458375 , 0.7674061 ]],\n \n         [[0.5266986 , 0.577679  , 0.6521888 ],\n          [0.51605314, 0.5670335 , 0.6415433 ],\n          [0.51052326, 0.56150365, 0.63601345],\n          ...,\n          [0.5518333 , 0.62634313, 0.74436516],\n          [0.55385035, 0.6302019 , 0.75021875],\n          [0.5528002 , 0.6331127 , 0.7554183 ]]],\n \n \n        ...,\n \n \n        [[[0.61769664, 0.6677214 , 0.73046654],\n          [0.61206216, 0.659121  , 0.7218661 ],\n          [0.61532545, 0.6623843 , 0.72512937],\n          ...,\n          [0.7133375 , 0.7603963 , 0.81529826],\n          [0.7052487 , 0.75230753, 0.8072095 ],\n          [0.69715995, 0.74421877, 0.7991207 ]],\n \n         [[0.6190216 , 0.66970885, 0.73245394],\n          [0.61249495, 0.65991884, 0.72266394],\n          [0.61466295, 0.66172177, 0.72446686],\n          ...,\n          [0.6617338 , 0.7087926 , 0.7636946 ],\n          [0.6660478 , 0.71310663, 0.7680086 ],\n          [0.67036176, 0.71742064, 0.7723226 ]],\n \n         [[0.6173919 , 0.6683723 , 0.73111737],\n          [0.6138199 , 0.66190624, 0.72465134],\n          [0.6140005 , 0.6610593 , 0.7238044 ],\n          ...,\n          [0.6897559 , 0.73681474, 0.7917167 ],\n          [0.6892166 , 0.73627543, 0.7911774 ],\n          [0.6886774 , 0.7357362 , 0.79063815]],\n \n         ...,\n \n         [[0.52936834, 0.5607409 , 0.61086404],\n          [0.5463435 , 0.5803532 , 0.6272359 ],\n          [0.530939  , 0.57015467, 0.61400545],\n          ...,\n          [0.61754674, 0.6566152 , 0.70411575],\n          [0.5718602 , 0.60766536, 0.6649558 ],\n          [0.520669  , 0.56422   , 0.62029123]],\n \n         [[0.49045697, 0.5218295 , 0.5689489 ],\n          [0.5172893 , 0.54997396, 0.59245515],\n          [0.509538  , 0.54874927, 0.58796716],\n          ...,\n          [0.6005436 , 0.6397593 , 0.6852724 ],\n          [0.58113486, 0.61760247, 0.6729055 ],\n          [0.5312686 , 0.5728322 , 0.62956595]],\n \n         [[0.49694   , 0.52931577, 0.57044655],\n          [0.47243425, 0.5053493 , 0.5454016 ],\n          [0.5084301 , 0.5449404 , 0.5823862 ],\n          ...,\n          [0.576032  , 0.61524767, 0.65877336],\n          [0.5904095 , 0.6275396 , 0.6808552 ],\n          [0.5418682 , 0.5814444 , 0.6388406 ]]],\n \n \n        [[[0.7701292 , 0.78973705, 0.80150175],\n          [0.7829795 , 0.80258733, 0.8174073 ],\n          [0.7890374 , 0.80864525, 0.8219344 ],\n          ...,\n          [0.7665068 , 0.78420717, 0.7959719 ],\n          [0.7650532 , 0.7807395 , 0.7925042 ],\n          [0.74015224, 0.7564297 , 0.7681944 ]],\n \n         [[0.7694944 , 0.78910226, 0.80111   ],\n          [0.79521453, 0.8148224 , 0.83009356],\n          [0.77647036, 0.7960782 , 0.8089162 ],\n          ...,\n          [0.7678601 , 0.7851094 , 0.7968741 ],\n          [0.76234645, 0.7780327 , 0.7897974 ],\n          [0.7333854 , 0.7501139 , 0.7618786 ]],\n \n         [[0.7955838 , 0.8151916 , 0.82765055],\n          [0.7891779 , 0.80878574, 0.824436  ],\n          [0.76244503, 0.7820529 , 0.79443973],\n          ...,\n          [0.7692135 , 0.78601164, 0.79777634],\n          [0.7596397 , 0.775326  , 0.7870907 ],\n          [0.72661847, 0.74379814, 0.75556284]],\n \n         ...,\n \n         [[0.70547986, 0.72116613, 0.71724457],\n          [0.69895303, 0.7146393 , 0.71071774],\n          [0.6812001 , 0.69688636, 0.6929648 ],\n          ...,\n          [0.5584675 , 0.5819969 , 0.5819969 ],\n          [0.5568628 , 0.5803922 , 0.5803922 ],\n          [0.5528607 , 0.5763901 , 0.5763901 ]],\n \n         [[0.7045776 , 0.7202639 , 0.71634233],\n          [0.69805074, 0.713737  , 0.70981544],\n          [0.67849326, 0.69417953, 0.69025797],\n          ...,\n          [0.5580164 , 0.5815458 , 0.5815458 ],\n          [0.5568628 , 0.5803922 , 0.5803922 ],\n          [0.5510562 , 0.5745856 , 0.5745856 ]],\n \n         [[0.7036754 , 0.71936166, 0.7154401 ],\n          [0.69536704, 0.7110533 , 0.70713174],\n          [0.67578655, 0.6914728 , 0.68755126],\n          ...,\n          [0.5575653 , 0.5810947 , 0.5810947 ],\n          [0.5568628 , 0.5803922 , 0.5803922 ],\n          [0.5492517 , 0.5727811 , 0.5727811 ]]],\n \n \n        [[[0.79215693, 0.79215693, 0.7843138 ],\n          [0.79215693, 0.79215693, 0.7843138 ],\n          [0.79215693, 0.79215693, 0.7843138 ],\n          ...,\n          [0.73333335, 0.73333335, 0.73333335],\n          [0.73333335, 0.73333335, 0.73333335],\n          [0.73333335, 0.73333335, 0.73333335]],\n \n         [[0.79215693, 0.79215693, 0.7843138 ],\n          [0.79215693, 0.79215693, 0.7843138 ],\n          [0.79215693, 0.79215693, 0.7843138 ],\n          ...,\n          [0.73333335, 0.73333335, 0.73333335],\n          [0.73333335, 0.73333335, 0.73333335],\n          [0.73333335, 0.73333335, 0.73333335]],\n \n         [[0.79215693, 0.79215693, 0.7843138 ],\n          [0.79215693, 0.79215693, 0.7843138 ],\n          [0.79215693, 0.79215693, 0.7843138 ],\n          ...,\n          [0.73333335, 0.73333335, 0.73333335],\n          [0.73333335, 0.73333335, 0.73333335],\n          [0.73333335, 0.73333335, 0.73333335]],\n \n         ...,\n \n         [[0.73789066, 0.7418122 , 0.7182828 ],\n          [0.7384016 , 0.74232316, 0.71879375],\n          [0.73075324, 0.7346748 , 0.7111454 ],\n          ...,\n          [0.6967648 , 0.69284326, 0.6732354 ],\n          [0.69635427, 0.6924327 , 0.67282486],\n          [0.6959438 , 0.6920222 , 0.67241436]],\n \n         [[0.72817665, 0.7320982 , 0.70856875],\n          [0.7406441 , 0.74456567, 0.72103626],\n          [0.76202327, 0.76594484, 0.7424154 ],\n          ...,\n          [0.6915635 , 0.6876419 , 0.6680341 ],\n          [0.69300026, 0.6890787 , 0.66947085],\n          [0.694437  , 0.69051546, 0.6709076 ]],\n \n         [[0.72562325, 0.7295448 , 0.7060154 ],\n          [0.7306686 , 0.7345902 , 0.71106076],\n          [0.744479  , 0.74840057, 0.72487116],\n          ...,\n          [0.69262815, 0.6887066 , 0.66909873],\n          [0.6903703 , 0.68644875, 0.6668409 ],\n          [0.68811256, 0.684191  , 0.66458315]]]], dtype=float32),\n array([[0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32))"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"vgg_model = tf.keras.applications.vgg16.VGG16()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T19:49:22.373727Z","iopub.execute_input":"2025-03-21T19:49:22.374070Z","iopub.status.idle":"2025-03-21T19:49:27.146960Z","shell.execute_reply.started":"2025-03-21T19:49:22.374042Z","shell.execute_reply":"2025-03-21T19:49:27.145983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# VGG","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG19, VGG16\n\n# 1. Load pre-trained VGG19 model (excluding top classification layer)\nbase_model = VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:51.762903Z","iopub.execute_input":"2025-04-04T20:08:51.763268Z","iopub.status.idle":"2025-04-04T20:08:52.102709Z","shell.execute_reply.started":"2025-04-04T20:08:51.763234Z","shell.execute_reply":"2025-04-04T20:08:52.101582Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Freeze all layers first\nbase_model.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:52.104989Z","iopub.execute_input":"2025-04-04T20:08:52.105222Z","iopub.status.idle":"2025-04-04T20:08:52.109464Z","shell.execute_reply.started":"2025-04-04T20:08:52.105203Z","shell.execute_reply":"2025-04-04T20:08:52.108513Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Unfreeze the last 5 layers\n# Count total layers in base model\nprint(len(base_model.layers))   # for reference\n\n# Unfreeze last 5 layers\nfor layer in base_model.layers[-5 : ] :\n    layer.trainable = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:08:52.269608Z","iopub.execute_input":"2025-04-04T20:08:52.269971Z","iopub.status.idle":"2025-04-04T20:08:52.274875Z","shell.execute_reply.started":"2025-04-04T20:08:52.269944Z","shell.execute_reply":"2025-04-04T20:08:52.273993Z"}},"outputs":[{"name":"stdout","text":"22\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\n# 2. Add custom top layers for  classification\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nDropout(0.)(x)\noutput_layer = Dense(9, activation='softmax')(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:15:06.254095Z","iopub.execute_input":"2025-04-04T20:15:06.254475Z","iopub.status.idle":"2025-04-04T20:15:06.278179Z","shell.execute_reply.started":"2025-04-04T20:15:06.254446Z","shell.execute_reply":"2025-04-04T20:15:06.277149Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"from tensorflow.keras.layers import BatchNormalization\nmodel.add(BatchNormalization())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:15:07.476335Z","iopub.execute_input":"2025-04-04T20:15:07.476720Z","iopub.status.idle":"2025-04-04T20:15:07.495008Z","shell.execute_reply.started":"2025-04-04T20:15:07.476678Z","shell.execute_reply":"2025-04-04T20:15:07.493779Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-6b6f52fa5058>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'add'"],"ename":"AttributeError","evalue":"'Functional' object has no attribute 'add'","output_type":"error"}],"execution_count":57},{"cell_type":"code","source":"from tensorflow.keras.models import Model\n\n# 3. add all layer togeather\nmodel = Model(inputs=base_model.input, outputs=output_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:17:10.875912Z","iopub.execute_input":"2025-04-04T20:17:10.876305Z","iopub.status.idle":"2025-04-04T20:17:10.883708Z","shell.execute_reply.started":"2025-04-04T20:17:10.876273Z","shell.execute_reply":"2025-04-04T20:17:10.882789Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# import tensorflow as tf\nfrom tensorflow.keras import backend as K\n\ndef focal_loss(alpha=0.25, gamma=2.0):\n    def loss(y_true, y_pred):\n        y_true = K.cast(y_true, K.floatx())\n        y_pred = K.clip(y_pred, 1e-7, 1 - 1e-7)\n        loss = -y_true * alpha * K.pow(1 - y_pred, gamma) * K.log(y_pred)\n        return K.sum(loss, axis=1)\n    return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:17:12.598896Z","iopub.execute_input":"2025-04-04T20:17:12.599215Z","iopub.status.idle":"2025-04-04T20:17:12.604626Z","shell.execute_reply.started":"2025-04-04T20:17:12.599190Z","shell.execute_reply":"2025-04-04T20:17:12.603702Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# 4. Compile the model\nmodel.compile(optimizer=Adam(learning_rate = 0.001), loss = focal_loss(), metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:17:13.376161Z","iopub.execute_input":"2025-04-04T20:17:13.376483Z","iopub.status.idle":"2025-04-04T20:17:13.386134Z","shell.execute_reply.started":"2025-04-04T20:17:13.376456Z","shell.execute_reply":"2025-04-04T20:17:13.385082Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# 5. Train the model\nbatch_size = 64\nepochs = 10\nmodel.fit(train_generator, epochs = epochs, validation_data = val_batch,  \n          class_weight=class_weight,  # Fix: Handling class imbalance\n          batch_size = batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T19:20:29.407474Z","iopub.execute_input":"2025-04-04T19:20:29.407826Z","iopub.status.idle":"2025-04-04T19:30:41.018276Z","shell.execute_reply.started":"2025-04-04T19:20:29.407796Z","shell.execute_reply":"2025-04-04T19:30:41.017438Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 706ms/step - accuracy: 0.1075 - loss: 0.4643 - val_accuracy: 0.1791 - val_loss: 0.3915\nEpoch 2/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 621ms/step - accuracy: 0.1891 - loss: 0.3645 - val_accuracy: 0.3172 - val_loss: 0.2997\nEpoch 3/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.3196 - loss: 0.2809 - val_accuracy: 0.3888 - val_loss: 0.2425\nEpoch 4/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 616ms/step - accuracy: 0.3590 - loss: 0.2388 - val_accuracy: 0.4110 - val_loss: 0.2290\nEpoch 5/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 615ms/step - accuracy: 0.4526 - loss: 0.1945 - val_accuracy: 0.4499 - val_loss: 0.1947\nEpoch 6/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 606ms/step - accuracy: 0.5070 - loss: 0.1608 - val_accuracy: 0.5279 - val_loss: 0.1701\nEpoch 7/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 606ms/step - accuracy: 0.5476 - loss: 0.1480 - val_accuracy: 0.5385 - val_loss: 0.1819\nEpoch 8/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 609ms/step - accuracy: 0.5760 - loss: 0.1382 - val_accuracy: 0.5764 - val_loss: 0.1636\nEpoch 9/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 614ms/step - accuracy: 0.5770 - loss: 0.1384 - val_accuracy: 0.5827 - val_loss: 0.1748\nEpoch 10/10\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 606ms/step - accuracy: 0.6489 - loss: 0.1137 - val_accuracy: 0.6438 - val_loss: 0.1245\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x78160ac44610>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# 4. Compile the model\nmodel.compile(optimizer=Adam(learning_rate = 0.00001), loss = focal_loss(), metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:17:31.686174Z","iopub.execute_input":"2025-04-04T20:17:31.686501Z","iopub.status.idle":"2025-04-04T20:17:31.695941Z","shell.execute_reply.started":"2025-04-04T20:17:31.686475Z","shell.execute_reply":"2025-04-04T20:17:31.695175Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, restore_best_weights = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:17:33.607770Z","iopub.execute_input":"2025-04-04T20:17:33.608073Z","iopub.status.idle":"2025-04-04T20:17:33.612490Z","shell.execute_reply.started":"2025-04-04T20:17:33.608049Z","shell.execute_reply":"2025-04-04T20:17:33.611343Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# 5. Train the model\nbatch_size = 64\nepochs = 30\nmodel.fit(train_generator, epochs = epochs, validation_data = val_batch,\n                    class_weight = class_weight,  # Fix: Handling class imbalance\n                    batch_size = batch_size)\n, callbacks = [early_stop]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:17:35.097007Z","iopub.execute_input":"2025-04-04T20:17:35.097313Z","iopub.status.idle":"2025-04-04T20:45:32.777285Z","shell.execute_reply.started":"2025-04-04T20:17:35.097289Z","shell.execute_reply":"2025-04-04T20:45:32.776506Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 654ms/step - accuracy: 0.1481 - loss: 0.4319 - val_accuracy: 0.4447 - val_loss: 0.2781\nEpoch 2/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 599ms/step - accuracy: 0.4529 - loss: 0.2488 - val_accuracy: 0.5153 - val_loss: 0.1920\nEpoch 3/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 592ms/step - accuracy: 0.5697 - loss: 0.1792 - val_accuracy: 0.6143 - val_loss: 0.1569\nEpoch 4/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 587ms/step - accuracy: 0.6450 - loss: 0.1423 - val_accuracy: 0.6006 - val_loss: 0.1551\nEpoch 5/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 590ms/step - accuracy: 0.6769 - loss: 0.1268 - val_accuracy: 0.6733 - val_loss: 0.1259\nEpoch 6/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 588ms/step - accuracy: 0.7153 - loss: 0.1083 - val_accuracy: 0.6365 - val_loss: 0.1342\nEpoch 7/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 582ms/step - accuracy: 0.7226 - loss: 0.0979 - val_accuracy: 0.6754 - val_loss: 0.1192\nEpoch 8/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 582ms/step - accuracy: 0.7442 - loss: 0.0915 - val_accuracy: 0.6765 - val_loss: 0.1181\nEpoch 9/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 592ms/step - accuracy: 0.7858 - loss: 0.0782 - val_accuracy: 0.7155 - val_loss: 0.1023\nEpoch 10/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 593ms/step - accuracy: 0.7795 - loss: 0.0770 - val_accuracy: 0.6955 - val_loss: 0.1078\nEpoch 11/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 593ms/step - accuracy: 0.7925 - loss: 0.0710 - val_accuracy: 0.7376 - val_loss: 0.0936\nEpoch 12/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 595ms/step - accuracy: 0.8020 - loss: 0.0633 - val_accuracy: 0.7123 - val_loss: 0.1011\nEpoch 13/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 584ms/step - accuracy: 0.8072 - loss: 0.0675 - val_accuracy: 0.7376 - val_loss: 0.0974\nEpoch 14/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 577ms/step - accuracy: 0.8279 - loss: 0.0554 - val_accuracy: 0.7566 - val_loss: 0.0868\nEpoch 15/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 575ms/step - accuracy: 0.8470 - loss: 0.0511 - val_accuracy: 0.7302 - val_loss: 0.0994\nEpoch 16/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.8357 - loss: 0.0541 - val_accuracy: 0.7439 - val_loss: 0.0939\nEpoch 17/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 567ms/step - accuracy: 0.8514 - loss: 0.0494 - val_accuracy: 0.7218 - val_loss: 0.1039\nEpoch 18/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 577ms/step - accuracy: 0.8520 - loss: 0.0499 - val_accuracy: 0.7482 - val_loss: 0.0944\nEpoch 19/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.8587 - loss: 0.0401 - val_accuracy: 0.7597 - val_loss: 0.0889\nEpoch 20/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.8867 - loss: 0.0361 - val_accuracy: 0.7555 - val_loss: 0.1050\nEpoch 21/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 565ms/step - accuracy: 0.8704 - loss: 0.0415 - val_accuracy: 0.7629 - val_loss: 0.0836\nEpoch 22/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 577ms/step - accuracy: 0.8600 - loss: 0.0433 - val_accuracy: 0.7682 - val_loss: 0.0819\nEpoch 23/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.8749 - loss: 0.0367 - val_accuracy: 0.7798 - val_loss: 0.0814\nEpoch 24/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 574ms/step - accuracy: 0.9111 - loss: 0.0281 - val_accuracy: 0.7576 - val_loss: 0.0912\nEpoch 25/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 577ms/step - accuracy: 0.8971 - loss: 0.0288 - val_accuracy: 0.7850 - val_loss: 0.0867\nEpoch 26/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 569ms/step - accuracy: 0.9113 - loss: 0.0278 - val_accuracy: 0.7619 - val_loss: 0.0913\nEpoch 27/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 561ms/step - accuracy: 0.9037 - loss: 0.0276 - val_accuracy: 0.7840 - val_loss: 0.0822\nEpoch 28/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 559ms/step - accuracy: 0.9048 - loss: 0.0269 - val_accuracy: 0.8008 - val_loss: 0.0775\nEpoch 29/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 559ms/step - accuracy: 0.9098 - loss: 0.0258 - val_accuracy: 0.7619 - val_loss: 0.0903\nEpoch 30/30\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 563ms/step - accuracy: 0.9218 - loss: 0.0216 - val_accuracy: 0.7682 - val_loss: 0.0856\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"('callbacks', '=', '[early_stop]')"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Train the model\nbatch_size = 64\nepochs = 200\nhistory = model.fit(train_generator, epochs = epochs, validation_data = val_batch, batch_size = batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T20:30:49.849622Z","iopub.execute_input":"2025-03-22T20:30:49.849943Z","iopub.status.idle":"2025-03-22T23:13:39.969602Z","shell.execute_reply.started":"2025-03-22T20:30:49.849919Z","shell.execute_reply":"2025-03-22T23:13:39.968808Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"overfitting // maybe use drop outs","metadata":{}},{"cell_type":"code","source":"y_test = test_batch.classes\ny_test[:150]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T02:21:25.192134Z","iopub.execute_input":"2025-04-04T02:21:25.192490Z","iopub.status.idle":"2025-04-04T02:21:25.198073Z","shell.execute_reply.started":"2025-04-04T02:21:25.192465Z","shell.execute_reply":"2025-04-04T02:21:25.197290Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# If test_batch is a generator (like ImageDataGenerator.flow_from_directory)\ny_pred_prob = model.predict(val_batch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T21:25:32.347063Z","iopub.execute_input":"2025-04-04T21:25:32.347369Z","iopub.status.idle":"2025-04-04T21:25:53.217682Z","shell.execute_reply.started":"2025-04-04T21:25:32.347346Z","shell.execute_reply":"2025-04-04T21:25:53.216714Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 409ms/step\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"# If using softmax, get the index of the highest predicted probability\ny_pred = np.argmax(y_pred_prob, axis = 1)\n\n# Get the true labels from the generator\ny_true = val_batch.classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T21:25:53.219355Z","iopub.execute_input":"2025-04-04T21:25:53.219741Z","iopub.status.idle":"2025-04-04T21:25:53.224005Z","shell.execute_reply.started":"2025-04-04T21:25:53.219715Z","shell.execute_reply":"2025-04-04T21:25:53.222919Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# If using flow_from_directory, use .class_indices to map labels\nlabels = list(val_batch.class_indices.keys())\n\nprint(classification_report(y_true, y_pred, target_names = labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T21:25:53.225487Z","iopub.execute_input":"2025-04-04T21:25:53.225781Z","iopub.status.idle":"2025-04-04T21:25:53.251816Z","shell.execute_reply.started":"2025-04-04T21:25:53.225757Z","shell.execute_reply":"2025-04-04T21:25:53.250871Z"}},"outputs":[{"name":"stdout","text":"                     precision    recall  f1-score   support\n\n          Cardboard       0.07      0.10      0.08        92\n      Food Organics       0.08      0.07      0.08        82\n              Glass       0.11      0.10      0.10        84\n              Metal       0.23      0.30      0.26       158\nMiscellaneous Trash       0.10      0.06      0.07        99\n              Paper       0.09      0.11      0.10       100\n            Plastic       0.21      0.14      0.17       184\n      Textile Trash       0.06      0.06      0.06        63\n         Vegetation       0.06      0.06      0.06        87\n\n           accuracy                           0.13       949\n          macro avg       0.11      0.11      0.11       949\n       weighted avg       0.13      0.13      0.13       949\n\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"there is something wrong here **","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB3\nbase_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:51:40.720353Z","iopub.execute_input":"2025-04-04T20:51:40.720723Z","iopub.status.idle":"2025-04-04T20:51:43.422238Z","shell.execute_reply.started":"2025-04-04T20:51:40.720692Z","shell.execute_reply":"2025-04-04T20:51:43.421445Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"# Freeze all layers first\nbase_model.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T03:50:50.328632Z","iopub.execute_input":"2025-04-04T03:50:50.328940Z","iopub.status.idle":"2025-04-04T03:50:50.338340Z","shell.execute_reply.started":"2025-04-04T03:50:50.328917Z","shell.execute_reply":"2025-04-04T03:50:50.337459Z"}},"outputs":[],"execution_count":130},{"cell_type":"code","source":"# Unfreeze the last 5 layers\n# Count total layers in base model\nprint(len(base_model.layers))   # for reference\n\n# Unfreeze last 5 layers\nfor layer in base_model.layers[-5 : ] :\n    layer.trainable = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:51:44.096323Z","iopub.execute_input":"2025-04-04T20:51:44.096772Z","iopub.status.idle":"2025-04-04T20:51:44.103509Z","shell.execute_reply.started":"2025-04-04T20:51:44.096732Z","shell.execute_reply":"2025-04-04T20:51:44.102428Z"}},"outputs":[{"name":"stdout","text":"385\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n\n# 2. Add custom top layers for  classification\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(512, activation='relu')(x)\nDropout(0.5)(x)\noutput_layer = Dense(9, activation='softmax')(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:51:54.099009Z","iopub.execute_input":"2025-04-04T20:51:54.099338Z","iopub.status.idle":"2025-04-04T20:51:54.125557Z","shell.execute_reply.started":"2025-04-04T20:51:54.099311Z","shell.execute_reply":"2025-04-04T20:51:54.124626Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"from tensorflow.keras.models import Model\n\n# 3. add all layer togeather\nmodel = Model(inputs=base_model.input, outputs=output_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:52:07.742168Z","iopub.execute_input":"2025-04-04T20:52:07.742489Z","iopub.status.idle":"2025-04-04T20:52:07.767367Z","shell.execute_reply.started":"2025-04-04T20:52:07.742466Z","shell.execute_reply":"2025-04-04T20:52:07.766689Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# 4. Compile the model\nmodel.compile(optimizer=Adam(learning_rate = 0.001),  loss = focal_loss(), metrics = ['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:53:10.211179Z","iopub.execute_input":"2025-04-04T20:53:10.211583Z","iopub.status.idle":"2025-04-04T20:53:10.222317Z","shell.execute_reply.started":"2025-04-04T20:53:10.211555Z","shell.execute_reply":"2025-04-04T20:53:10.221375Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n\n# Early Stopping to Prevent Overfitting\n# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 3, restore_best_weights = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T20:53:13.908155Z","iopub.execute_input":"2025-04-04T20:53:13.908494Z","iopub.status.idle":"2025-04-04T20:53:13.912846Z","shell.execute_reply.started":"2025-04-04T20:53:13.908465Z","shell.execute_reply":"2025-04-04T20:53:13.911755Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"# 5. Train the model\nbatch_size = 64\nepochs = 200\nmodel.fit(train_generator, epochs = epochs, validation_data = val_batch,\n                    class_weight=class_weight,  # Fix: Handling class imbalance\n                    batch_size = batch_size)\n, callbacks = [early_stop]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T21:31:45.515740Z","iopub.execute_input":"2025-04-04T21:31:45.516130Z","iopub.status.idle":"2025-04-05T00:44:26.308181Z","shell.execute_reply.started":"2025-04-04T21:31:45.516098Z","shell.execute_reply":"2025-04-05T00:44:26.307303Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 625ms/step - accuracy: 0.9651 - loss: 0.0094 - val_accuracy: 0.7208 - val_loss: 0.1802\nEpoch 2/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 627ms/step - accuracy: 0.9558 - loss: 0.0114 - val_accuracy: 0.8788 - val_loss: 0.0605\nEpoch 3/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 622ms/step - accuracy: 0.9711 - loss: 0.0085 - val_accuracy: 0.8303 - val_loss: 0.0984\nEpoch 4/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 637ms/step - accuracy: 0.9668 - loss: 0.0103 - val_accuracy: 0.7682 - val_loss: 0.1095\nEpoch 5/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 627ms/step - accuracy: 0.9787 - loss: 0.0049 - val_accuracy: 0.8577 - val_loss: 0.0867\nEpoch 6/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 621ms/step - accuracy: 0.9830 - loss: 0.0047 - val_accuracy: 0.8599 - val_loss: 0.0787\nEpoch 7/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 639ms/step - accuracy: 0.9774 - loss: 0.0058 - val_accuracy: 0.7998 - val_loss: 0.1078\nEpoch 8/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 643ms/step - accuracy: 0.9561 - loss: 0.0113 - val_accuracy: 0.7808 - val_loss: 0.1049\nEpoch 9/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 618ms/step - accuracy: 0.9755 - loss: 0.0081 - val_accuracy: 0.7734 - val_loss: 0.1258\nEpoch 10/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 620ms/step - accuracy: 0.9539 - loss: 0.0126 - val_accuracy: 0.7787 - val_loss: 0.1532\nEpoch 11/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 622ms/step - accuracy: 0.9410 - loss: 0.0241 - val_accuracy: 0.7092 - val_loss: 0.1703\nEpoch 12/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 627ms/step - accuracy: 0.9772 - loss: 0.0076 - val_accuracy: 0.8251 - val_loss: 0.1094\nEpoch 13/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 616ms/step - accuracy: 0.9808 - loss: 0.0057 - val_accuracy: 0.7966 - val_loss: 0.1352\nEpoch 14/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.9636 - loss: 0.0122 - val_accuracy: 0.7260 - val_loss: 0.1458\nEpoch 15/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 590ms/step - accuracy: 0.9556 - loss: 0.0112 - val_accuracy: 0.7829 - val_loss: 0.1024\nEpoch 16/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 621ms/step - accuracy: 0.9704 - loss: 0.0070 - val_accuracy: 0.6807 - val_loss: 0.2024\nEpoch 17/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 618ms/step - accuracy: 0.9503 - loss: 0.0161 - val_accuracy: 0.7397 - val_loss: 0.1610\nEpoch 18/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 635ms/step - accuracy: 0.9485 - loss: 0.0168 - val_accuracy: 0.8388 - val_loss: 0.0861\nEpoch 19/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 634ms/step - accuracy: 0.9598 - loss: 0.0130 - val_accuracy: 0.8388 - val_loss: 0.0748\nEpoch 20/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 635ms/step - accuracy: 0.9730 - loss: 0.0077 - val_accuracy: 0.7387 - val_loss: 0.1311\nEpoch 21/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 633ms/step - accuracy: 0.9670 - loss: 0.0094 - val_accuracy: 0.7914 - val_loss: 0.1188\nEpoch 22/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 601ms/step - accuracy: 0.9673 - loss: 0.0124 - val_accuracy: 0.8757 - val_loss: 0.0622\nEpoch 23/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 602ms/step - accuracy: 0.9861 - loss: 0.0043 - val_accuracy: 0.8135 - val_loss: 0.1033\nEpoch 24/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 619ms/step - accuracy: 0.9770 - loss: 0.0064 - val_accuracy: 0.8093 - val_loss: 0.1088\nEpoch 25/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 610ms/step - accuracy: 0.9634 - loss: 0.0106 - val_accuracy: 0.8156 - val_loss: 0.1103\nEpoch 26/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 603ms/step - accuracy: 0.9820 - loss: 0.0061 - val_accuracy: 0.8135 - val_loss: 0.1058\nEpoch 27/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.9741 - loss: 0.0074 - val_accuracy: 0.8303 - val_loss: 0.0896\nEpoch 28/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 608ms/step - accuracy: 0.9756 - loss: 0.0076 - val_accuracy: 0.8156 - val_loss: 0.1035\nEpoch 29/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 601ms/step - accuracy: 0.9647 - loss: 0.0103 - val_accuracy: 0.6175 - val_loss: 0.2688\nEpoch 30/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 593ms/step - accuracy: 0.9600 - loss: 0.0130 - val_accuracy: 0.7998 - val_loss: 0.0951\nEpoch 31/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.9716 - loss: 0.0081 - val_accuracy: 0.7218 - val_loss: 0.1993\nEpoch 32/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 596ms/step - accuracy: 0.9854 - loss: 0.0042 - val_accuracy: 0.8620 - val_loss: 0.0746\nEpoch 33/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 597ms/step - accuracy: 0.9785 - loss: 0.0058 - val_accuracy: 0.8662 - val_loss: 0.0706\nEpoch 34/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 592ms/step - accuracy: 0.9815 - loss: 0.0049 - val_accuracy: 0.8008 - val_loss: 0.0992\nEpoch 35/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 583ms/step - accuracy: 0.9810 - loss: 0.0065 - val_accuracy: 0.8588 - val_loss: 0.0863\nEpoch 36/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 594ms/step - accuracy: 0.9704 - loss: 0.0094 - val_accuracy: 0.7587 - val_loss: 0.1285\nEpoch 37/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 606ms/step - accuracy: 0.9800 - loss: 0.0057 - val_accuracy: 0.8419 - val_loss: 0.1020\nEpoch 38/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 605ms/step - accuracy: 0.9797 - loss: 0.0069 - val_accuracy: 0.7914 - val_loss: 0.1141\nEpoch 39/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 634ms/step - accuracy: 0.9731 - loss: 0.0094 - val_accuracy: 0.8493 - val_loss: 0.0962\nEpoch 40/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 633ms/step - accuracy: 0.9797 - loss: 0.0042 - val_accuracy: 0.8356 - val_loss: 0.0929\nEpoch 41/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 622ms/step - accuracy: 0.9822 - loss: 0.0051 - val_accuracy: 0.8314 - val_loss: 0.1021\nEpoch 42/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 613ms/step - accuracy: 0.9802 - loss: 0.0056 - val_accuracy: 0.7998 - val_loss: 0.1222\nEpoch 43/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 625ms/step - accuracy: 0.9816 - loss: 0.0047 - val_accuracy: 0.8135 - val_loss: 0.1027\nEpoch 44/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 623ms/step - accuracy: 0.9762 - loss: 0.0068 - val_accuracy: 0.7576 - val_loss: 0.1498\nEpoch 45/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 615ms/step - accuracy: 0.9634 - loss: 0.0117 - val_accuracy: 0.7545 - val_loss: 0.1665\nEpoch 46/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 610ms/step - accuracy: 0.9707 - loss: 0.0137 - val_accuracy: 0.7861 - val_loss: 0.1362\nEpoch 47/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 602ms/step - accuracy: 0.9823 - loss: 0.0072 - val_accuracy: 0.8483 - val_loss: 0.0914\nEpoch 48/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 610ms/step - accuracy: 0.9758 - loss: 0.0089 - val_accuracy: 0.8693 - val_loss: 0.0693\nEpoch 49/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 605ms/step - accuracy: 0.9736 - loss: 0.0070 - val_accuracy: 0.7534 - val_loss: 0.1418\nEpoch 50/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 591ms/step - accuracy: 0.9786 - loss: 0.0060 - val_accuracy: 0.8051 - val_loss: 0.1053\nEpoch 51/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 596ms/step - accuracy: 0.9756 - loss: 0.0062 - val_accuracy: 0.8325 - val_loss: 0.0679\nEpoch 52/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 586ms/step - accuracy: 0.9865 - loss: 0.0027 - val_accuracy: 0.8641 - val_loss: 0.0719\nEpoch 53/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 605ms/step - accuracy: 0.9918 - loss: 0.0039 - val_accuracy: 0.8261 - val_loss: 0.0938\nEpoch 54/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 618ms/step - accuracy: 0.9790 - loss: 0.0055 - val_accuracy: 0.7850 - val_loss: 0.1416\nEpoch 55/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 603ms/step - accuracy: 0.9707 - loss: 0.0094 - val_accuracy: 0.8251 - val_loss: 0.1023\nEpoch 56/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 609ms/step - accuracy: 0.9867 - loss: 0.0041 - val_accuracy: 0.7661 - val_loss: 0.1398\nEpoch 57/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 595ms/step - accuracy: 0.9697 - loss: 0.0100 - val_accuracy: 0.8388 - val_loss: 0.0853\nEpoch 58/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 611ms/step - accuracy: 0.9797 - loss: 0.0064 - val_accuracy: 0.6923 - val_loss: 0.2268\nEpoch 59/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 614ms/step - accuracy: 0.9640 - loss: 0.0152 - val_accuracy: 0.6280 - val_loss: 0.3233\nEpoch 60/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.9742 - loss: 0.0069 - val_accuracy: 0.6828 - val_loss: 0.2362\nEpoch 61/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.9717 - loss: 0.0073 - val_accuracy: 0.8514 - val_loss: 0.0973\nEpoch 62/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 596ms/step - accuracy: 0.9801 - loss: 0.0065 - val_accuracy: 0.7956 - val_loss: 0.1271\nEpoch 63/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 586ms/step - accuracy: 0.9824 - loss: 0.0062 - val_accuracy: 0.8714 - val_loss: 0.0781\nEpoch 64/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 588ms/step - accuracy: 0.9875 - loss: 0.0038 - val_accuracy: 0.8293 - val_loss: 0.1034\nEpoch 65/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 590ms/step - accuracy: 0.9830 - loss: 0.0051 - val_accuracy: 0.7197 - val_loss: 0.2142\nEpoch 66/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 582ms/step - accuracy: 0.9859 - loss: 0.0060 - val_accuracy: 0.8272 - val_loss: 0.1289\nEpoch 67/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9817 - loss: 0.0057 - val_accuracy: 0.8314 - val_loss: 0.1060\nEpoch 68/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 576ms/step - accuracy: 0.9825 - loss: 0.0038 - val_accuracy: 0.8093 - val_loss: 0.1457\nEpoch 69/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 582ms/step - accuracy: 0.9856 - loss: 0.0037 - val_accuracy: 0.8820 - val_loss: 0.0638\nEpoch 70/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 579ms/step - accuracy: 0.9913 - loss: 0.0030 - val_accuracy: 0.8704 - val_loss: 0.0736\nEpoch 71/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 575ms/step - accuracy: 0.9860 - loss: 0.0041 - val_accuracy: 0.8166 - val_loss: 0.1164\nEpoch 72/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 576ms/step - accuracy: 0.9772 - loss: 0.0062 - val_accuracy: 0.8177 - val_loss: 0.0877\nEpoch 73/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.9767 - loss: 0.0088 - val_accuracy: 0.7387 - val_loss: 0.1753\nEpoch 74/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9828 - loss: 0.0041 - val_accuracy: 0.8251 - val_loss: 0.0996\nEpoch 75/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9903 - loss: 0.0028 - val_accuracy: 0.8725 - val_loss: 0.0820\nEpoch 76/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 590ms/step - accuracy: 0.9875 - loss: 0.0044 - val_accuracy: 0.8430 - val_loss: 0.0834\nEpoch 77/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9843 - loss: 0.0044 - val_accuracy: 0.8114 - val_loss: 0.1044\nEpoch 78/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 595ms/step - accuracy: 0.9846 - loss: 0.0031 - val_accuracy: 0.8103 - val_loss: 0.0990\nEpoch 79/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 608ms/step - accuracy: 0.9841 - loss: 0.0060 - val_accuracy: 0.8809 - val_loss: 0.0707\nEpoch 80/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 613ms/step - accuracy: 0.9842 - loss: 0.0043 - val_accuracy: 0.5806 - val_loss: 0.3836\nEpoch 81/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 604ms/step - accuracy: 0.9814 - loss: 0.0060 - val_accuracy: 0.7956 - val_loss: 0.1295\nEpoch 82/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 599ms/step - accuracy: 0.9723 - loss: 0.0081 - val_accuracy: 0.7966 - val_loss: 0.1124\nEpoch 83/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9752 - loss: 0.0080 - val_accuracy: 0.8409 - val_loss: 0.0933\nEpoch 84/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 601ms/step - accuracy: 0.9857 - loss: 0.0054 - val_accuracy: 0.8546 - val_loss: 0.0883\nEpoch 85/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 584ms/step - accuracy: 0.9861 - loss: 0.0063 - val_accuracy: 0.8356 - val_loss: 0.0947\nEpoch 86/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 602ms/step - accuracy: 0.9915 - loss: 0.0031 - val_accuracy: 0.7977 - val_loss: 0.1232\nEpoch 87/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 601ms/step - accuracy: 0.9814 - loss: 0.0045 - val_accuracy: 0.8419 - val_loss: 0.0893\nEpoch 88/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 599ms/step - accuracy: 0.9857 - loss: 0.0039 - val_accuracy: 0.8040 - val_loss: 0.1062\nEpoch 89/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 599ms/step - accuracy: 0.9795 - loss: 0.0053 - val_accuracy: 0.8135 - val_loss: 0.0978\nEpoch 90/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 583ms/step - accuracy: 0.9931 - loss: 0.0029 - val_accuracy: 0.7387 - val_loss: 0.1886\nEpoch 91/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 564ms/step - accuracy: 0.9897 - loss: 0.0027 - val_accuracy: 0.7313 - val_loss: 0.1904\nEpoch 92/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 580ms/step - accuracy: 0.9811 - loss: 0.0065 - val_accuracy: 0.8135 - val_loss: 0.1183\nEpoch 93/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 572ms/step - accuracy: 0.9876 - loss: 0.0041 - val_accuracy: 0.8166 - val_loss: 0.1340\nEpoch 94/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 572ms/step - accuracy: 0.9858 - loss: 0.0037 - val_accuracy: 0.8282 - val_loss: 0.1008\nEpoch 95/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 587ms/step - accuracy: 0.9797 - loss: 0.0061 - val_accuracy: 0.8177 - val_loss: 0.1278\nEpoch 96/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 582ms/step - accuracy: 0.9531 - loss: 0.0180 - val_accuracy: 0.5743 - val_loss: 0.2823\nEpoch 97/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 579ms/step - accuracy: 0.9830 - loss: 0.0045 - val_accuracy: 0.8483 - val_loss: 0.0808\nEpoch 98/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 583ms/step - accuracy: 0.9943 - loss: 0.0014 - val_accuracy: 0.8872 - val_loss: 0.0656\nEpoch 99/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 576ms/step - accuracy: 0.9884 - loss: 0.0025 - val_accuracy: 0.7977 - val_loss: 0.1468\nEpoch 100/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 583ms/step - accuracy: 0.9811 - loss: 0.0054 - val_accuracy: 0.8493 - val_loss: 0.0909\nEpoch 101/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 580ms/step - accuracy: 0.9714 - loss: 0.0097 - val_accuracy: 0.8335 - val_loss: 0.1069\nEpoch 102/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 577ms/step - accuracy: 0.9883 - loss: 0.0029 - val_accuracy: 0.8651 - val_loss: 0.0890\nEpoch 103/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9942 - loss: 0.0016 - val_accuracy: 0.8662 - val_loss: 0.0771\nEpoch 104/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 597ms/step - accuracy: 0.9908 - loss: 0.0030 - val_accuracy: 0.8904 - val_loss: 0.0685\nEpoch 105/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 596ms/step - accuracy: 0.9903 - loss: 0.0026 - val_accuracy: 0.8588 - val_loss: 0.0816\nEpoch 106/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 572ms/step - accuracy: 0.9924 - loss: 0.0014 - val_accuracy: 0.8704 - val_loss: 0.0688\nEpoch 107/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 588ms/step - accuracy: 0.9991 - loss: 4.1827e-04 - val_accuracy: 0.7882 - val_loss: 0.1553\nEpoch 108/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 589ms/step - accuracy: 0.9891 - loss: 0.0045 - val_accuracy: 0.8219 - val_loss: 0.1105\nEpoch 109/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.9951 - loss: 0.0016 - val_accuracy: 0.8830 - val_loss: 0.0673\nEpoch 110/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 583ms/step - accuracy: 0.9929 - loss: 0.0013 - val_accuracy: 0.8704 - val_loss: 0.0884\nEpoch 111/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 595ms/step - accuracy: 0.9861 - loss: 0.0042 - val_accuracy: 0.4837 - val_loss: 0.4372\nEpoch 112/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 590ms/step - accuracy: 0.9609 - loss: 0.0117 - val_accuracy: 0.7450 - val_loss: 0.1584\nEpoch 113/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 581ms/step - accuracy: 0.9708 - loss: 0.0079 - val_accuracy: 0.8061 - val_loss: 0.1166\nEpoch 114/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 581ms/step - accuracy: 0.9858 - loss: 0.0038 - val_accuracy: 0.8188 - val_loss: 0.1029\nEpoch 115/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 588ms/step - accuracy: 0.9788 - loss: 0.0049 - val_accuracy: 0.8462 - val_loss: 0.1022\nEpoch 116/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 585ms/step - accuracy: 0.9936 - loss: 0.0017 - val_accuracy: 0.8124 - val_loss: 0.1249\nEpoch 117/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 581ms/step - accuracy: 0.9924 - loss: 0.0040 - val_accuracy: 0.8440 - val_loss: 0.1110\nEpoch 118/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 581ms/step - accuracy: 0.9888 - loss: 0.0027 - val_accuracy: 0.8325 - val_loss: 0.1081\nEpoch 119/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 588ms/step - accuracy: 0.9908 - loss: 0.0015 - val_accuracy: 0.8451 - val_loss: 0.0953\nEpoch 120/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 581ms/step - accuracy: 0.9913 - loss: 0.0014 - val_accuracy: 0.8008 - val_loss: 0.1484\nEpoch 121/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 584ms/step - accuracy: 0.9871 - loss: 0.0044 - val_accuracy: 0.5090 - val_loss: 0.5129\nEpoch 122/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 579ms/step - accuracy: 0.9684 - loss: 0.0108 - val_accuracy: 0.8567 - val_loss: 0.1018\nEpoch 123/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.9781 - loss: 0.0051 - val_accuracy: 0.7123 - val_loss: 0.1907\nEpoch 124/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 598ms/step - accuracy: 0.9785 - loss: 0.0074 - val_accuracy: 0.8925 - val_loss: 0.0646\nEpoch 125/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 591ms/step - accuracy: 0.9920 - loss: 0.0018 - val_accuracy: 0.8788 - val_loss: 0.0792\nEpoch 126/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 591ms/step - accuracy: 0.9951 - loss: 0.0019 - val_accuracy: 0.8556 - val_loss: 0.0850\nEpoch 127/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 592ms/step - accuracy: 0.9870 - loss: 0.0029 - val_accuracy: 0.8546 - val_loss: 0.1057\nEpoch 128/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 591ms/step - accuracy: 0.9860 - loss: 0.0039 - val_accuracy: 0.7808 - val_loss: 0.1594\nEpoch 129/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 615ms/step - accuracy: 0.9796 - loss: 0.0063 - val_accuracy: 0.8451 - val_loss: 0.1042\nEpoch 130/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 617ms/step - accuracy: 0.9888 - loss: 0.0023 - val_accuracy: 0.8704 - val_loss: 0.0890\nEpoch 131/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 643ms/step - accuracy: 0.9934 - loss: 0.0017 - val_accuracy: 0.8188 - val_loss: 0.1247\nEpoch 132/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 645ms/step - accuracy: 0.9842 - loss: 0.0052 - val_accuracy: 0.8799 - val_loss: 0.0767\nEpoch 133/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 644ms/step - accuracy: 0.9975 - loss: 9.8727e-04 - val_accuracy: 0.9083 - val_loss: 0.0657\nEpoch 134/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.9920 - loss: 0.0011 - val_accuracy: 0.8904 - val_loss: 0.0773\nEpoch 135/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.9932 - loss: 0.0028 - val_accuracy: 0.8293 - val_loss: 0.1036\nEpoch 136/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 642ms/step - accuracy: 0.9746 - loss: 0.0056 - val_accuracy: 0.8535 - val_loss: 0.0789\nEpoch 137/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 651ms/step - accuracy: 0.9870 - loss: 0.0049 - val_accuracy: 0.8040 - val_loss: 0.1340\nEpoch 138/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 648ms/step - accuracy: 0.9798 - loss: 0.0085 - val_accuracy: 0.7418 - val_loss: 0.1608\nEpoch 139/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 632ms/step - accuracy: 0.9818 - loss: 0.0051 - val_accuracy: 0.8493 - val_loss: 0.0873\nEpoch 140/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 686ms/step - accuracy: 0.9846 - loss: 0.0060 - val_accuracy: 0.7808 - val_loss: 0.1489\nEpoch 141/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 607ms/step - accuracy: 0.9866 - loss: 0.0033 - val_accuracy: 0.8599 - val_loss: 0.0884\nEpoch 142/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 624ms/step - accuracy: 0.9924 - loss: 0.0027 - val_accuracy: 0.7840 - val_loss: 0.1469\nEpoch 143/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 620ms/step - accuracy: 0.9877 - loss: 0.0039 - val_accuracy: 0.8145 - val_loss: 0.1128\nEpoch 144/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 643ms/step - accuracy: 0.9887 - loss: 0.0028 - val_accuracy: 0.8999 - val_loss: 0.0648\nEpoch 145/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.9974 - loss: 6.1278e-04 - val_accuracy: 0.8830 - val_loss: 0.0793\nEpoch 146/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 637ms/step - accuracy: 0.9892 - loss: 0.0038 - val_accuracy: 0.7671 - val_loss: 0.1240\nEpoch 147/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 633ms/step - accuracy: 0.9964 - loss: 0.0011 - val_accuracy: 0.8651 - val_loss: 0.0894\nEpoch 148/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 628ms/step - accuracy: 0.9928 - loss: 0.0019 - val_accuracy: 0.8219 - val_loss: 0.1236\nEpoch 149/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 627ms/step - accuracy: 0.9863 - loss: 0.0032 - val_accuracy: 0.8514 - val_loss: 0.0936\nEpoch 150/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 619ms/step - accuracy: 0.9902 - loss: 0.0021 - val_accuracy: 0.8051 - val_loss: 0.1265\nEpoch 151/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 640ms/step - accuracy: 0.9853 - loss: 0.0069 - val_accuracy: 0.7387 - val_loss: 0.1543\nEpoch 152/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 640ms/step - accuracy: 0.9802 - loss: 0.0067 - val_accuracy: 0.8398 - val_loss: 0.0803\nEpoch 153/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 643ms/step - accuracy: 0.9874 - loss: 0.0040 - val_accuracy: 0.8061 - val_loss: 0.1150\nEpoch 154/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 615ms/step - accuracy: 0.9762 - loss: 0.0054 - val_accuracy: 0.8609 - val_loss: 0.0873\nEpoch 155/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 637ms/step - accuracy: 0.9881 - loss: 0.0031 - val_accuracy: 0.8641 - val_loss: 0.0807\nEpoch 156/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 628ms/step - accuracy: 0.9883 - loss: 0.0036 - val_accuracy: 0.8630 - val_loss: 0.0876\nEpoch 157/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 617ms/step - accuracy: 0.9837 - loss: 0.0043 - val_accuracy: 0.8788 - val_loss: 0.0837\nEpoch 158/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 627ms/step - accuracy: 0.9912 - loss: 0.0057 - val_accuracy: 0.8588 - val_loss: 0.0769\nEpoch 159/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 630ms/step - accuracy: 0.9816 - loss: 0.0061 - val_accuracy: 0.8725 - val_loss: 0.0595\nEpoch 160/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 636ms/step - accuracy: 0.9886 - loss: 0.0028 - val_accuracy: 0.8620 - val_loss: 0.0751\nEpoch 161/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 644ms/step - accuracy: 0.9903 - loss: 0.0021 - val_accuracy: 0.8240 - val_loss: 0.1064\nEpoch 162/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 643ms/step - accuracy: 0.9877 - loss: 0.0029 - val_accuracy: 0.5869 - val_loss: 0.3318\nEpoch 163/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 628ms/step - accuracy: 0.9813 - loss: 0.0050 - val_accuracy: 0.7756 - val_loss: 0.1597\nEpoch 164/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 621ms/step - accuracy: 0.9963 - loss: 7.2292e-04 - val_accuracy: 0.8567 - val_loss: 0.0980\nEpoch 165/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 624ms/step - accuracy: 0.9968 - loss: 7.0544e-04 - val_accuracy: 0.8809 - val_loss: 0.0717\nEpoch 166/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 633ms/step - accuracy: 0.9968 - loss: 0.0023 - val_accuracy: 0.8820 - val_loss: 0.0659\nEpoch 167/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 619ms/step - accuracy: 0.9957 - loss: 0.0013 - val_accuracy: 0.8388 - val_loss: 0.1097\nEpoch 168/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 625ms/step - accuracy: 0.9873 - loss: 0.0054 - val_accuracy: 0.8188 - val_loss: 0.1067\nEpoch 169/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 616ms/step - accuracy: 0.9911 - loss: 0.0033 - val_accuracy: 0.8103 - val_loss: 0.1193\nEpoch 170/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 599ms/step - accuracy: 0.9917 - loss: 0.0023 - val_accuracy: 0.8577 - val_loss: 0.0813\nEpoch 171/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 600ms/step - accuracy: 0.9879 - loss: 0.0036 - val_accuracy: 0.8725 - val_loss: 0.0741\nEpoch 172/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 621ms/step - accuracy: 0.9953 - loss: 6.9976e-04 - val_accuracy: 0.8672 - val_loss: 0.0805\nEpoch 173/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 611ms/step - accuracy: 0.9998 - loss: 2.7682e-04 - val_accuracy: 0.8746 - val_loss: 0.0829\nEpoch 174/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 608ms/step - accuracy: 0.9950 - loss: 0.0017 - val_accuracy: 0.8683 - val_loss: 0.0722\nEpoch 175/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 604ms/step - accuracy: 0.9794 - loss: 0.0080 - val_accuracy: 0.8093 - val_loss: 0.1286\nEpoch 176/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 601ms/step - accuracy: 0.9864 - loss: 0.0040 - val_accuracy: 0.8135 - val_loss: 0.1071\nEpoch 177/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 611ms/step - accuracy: 0.9841 - loss: 0.0043 - val_accuracy: 0.7734 - val_loss: 0.1122\nEpoch 178/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 605ms/step - accuracy: 0.9806 - loss: 0.0053 - val_accuracy: 0.8166 - val_loss: 0.1018\nEpoch 179/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 610ms/step - accuracy: 0.9871 - loss: 0.0037 - val_accuracy: 0.8862 - val_loss: 0.0580\nEpoch 180/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 620ms/step - accuracy: 0.9941 - loss: 0.0018 - val_accuracy: 0.8883 - val_loss: 0.0655\nEpoch 181/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 604ms/step - accuracy: 0.9931 - loss: 0.0012 - val_accuracy: 0.9009 - val_loss: 0.0530\nEpoch 182/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 613ms/step - accuracy: 0.9980 - loss: 4.2110e-04 - val_accuracy: 0.8957 - val_loss: 0.0592\nEpoch 183/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 610ms/step - accuracy: 0.9994 - loss: 1.6947e-04 - val_accuracy: 0.9041 - val_loss: 0.0539\nEpoch 184/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 602ms/step - accuracy: 0.9976 - loss: 5.3915e-04 - val_accuracy: 0.8567 - val_loss: 0.0890\nEpoch 185/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 590ms/step - accuracy: 0.9956 - loss: 0.0020 - val_accuracy: 0.7745 - val_loss: 0.1513\nEpoch 186/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.9876 - loss: 0.0049 - val_accuracy: 0.8325 - val_loss: 0.1033\nEpoch 187/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 589ms/step - accuracy: 0.9855 - loss: 0.0041 - val_accuracy: 0.6660 - val_loss: 0.3294\nEpoch 188/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 575ms/step - accuracy: 0.9808 - loss: 0.0050 - val_accuracy: 0.7482 - val_loss: 0.1844\nEpoch 189/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 572ms/step - accuracy: 0.9819 - loss: 0.0034 - val_accuracy: 0.5479 - val_loss: 0.4353\nEpoch 190/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 579ms/step - accuracy: 0.9894 - loss: 0.0032 - val_accuracy: 0.6512 - val_loss: 0.3286\nEpoch 191/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 577ms/step - accuracy: 0.9926 - loss: 0.0020 - val_accuracy: 0.8261 - val_loss: 0.1019\nEpoch 192/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 579ms/step - accuracy: 0.9944 - loss: 0.0029 - val_accuracy: 0.7503 - val_loss: 0.1746\nEpoch 193/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 570ms/step - accuracy: 0.9885 - loss: 0.0025 - val_accuracy: 0.7345 - val_loss: 0.1902\nEpoch 194/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 569ms/step - accuracy: 0.9830 - loss: 0.0046 - val_accuracy: 0.7966 - val_loss: 0.1330\nEpoch 195/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 575ms/step - accuracy: 0.9897 - loss: 0.0028 - val_accuracy: 0.8251 - val_loss: 0.1038\nEpoch 196/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 578ms/step - accuracy: 0.9882 - loss: 0.0041 - val_accuracy: 0.7250 - val_loss: 0.1779\nEpoch 197/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 571ms/step - accuracy: 0.9911 - loss: 0.0024 - val_accuracy: 0.8641 - val_loss: 0.0876\nEpoch 198/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 573ms/step - accuracy: 0.9915 - loss: 0.0026 - val_accuracy: 0.8788 - val_loss: 0.0717\nEpoch 199/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 574ms/step - accuracy: 0.9955 - loss: 0.0020 - val_accuracy: 0.8440 - val_loss: 0.0991\nEpoch 200/200\n\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 580ms/step - accuracy: 0.9826 - loss: 0.0055 - val_accuracy: 0.8008 - val_loss: 0.1205\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"('callbacks', '=', '[early_stop]')"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\n# Predict on validation data\ny_pred_prob = model.predict(val_batch)  \ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Get true labels from the generator\ny_true = val_batch.classes  \n\n# Get class labels\nlabels = list(val_batch.class_indices.keys())\n\n# Calculate validation accuracy\nval_accuracy = accuracy_score(y_true, y_pred)\n\n# Print classification report\nprint(\"Validation Classification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=labels))\n\n# Print validation accuracy\nprint(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n\n# Get training accuracy from history object\nif 'accuracy' in history.history and 'val_accuracy' in history.history:\n    train_accuracy = history.history['accuracy'][-1]  # Last epoch train accuracy\n    print(f\"Train Accuracy: {train_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T00:44:26.309491Z","iopub.execute_input":"2025-04-05T00:44:26.309961Z","iopub.status.idle":"2025-04-05T00:44:31.256240Z","shell.execute_reply.started":"2025-04-05T00:44:26.309915Z","shell.execute_reply":"2025-04-05T00:44:31.255041Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step\nValidation Classification Report:\n\n                     precision    recall  f1-score   support\n\n          Cardboard       0.07      0.12      0.09        92\n      Food Organics       0.07      0.06      0.07        82\n              Glass       0.09      0.10      0.09        84\n              Metal       0.12      0.13      0.13       158\nMiscellaneous Trash       0.09      0.07      0.08        99\n              Paper       0.13      0.14      0.14       100\n            Plastic       0.19      0.14      0.16       184\n      Textile Trash       0.06      0.05      0.05        63\n         Vegetation       0.10      0.11      0.11        87\n\n           accuracy                           0.11       949\n          macro avg       0.10      0.10      0.10       949\n       weighted avg       0.11      0.11      0.11       949\n\n\nValidation Accuracy: 0.1096\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-56ccf534b98b>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Get training accuracy from history object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'accuracy'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Last epoch train accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Accuracy: {train_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"],"ename":"NameError","evalue":"name 'history' is not defined","output_type":"error"}],"execution_count":78},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}